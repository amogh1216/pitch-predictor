{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import model\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "reading batter csv\n",
      "read batter csv\n",
      "reading pitcher csv\n",
      "read pitcher csv\n",
      "reading dataset csv\n",
      "read dataset csv\n",
      "processing train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing plate appearances: 100%|██████████| 179716/179716 [02:33<00:00, 1173.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing val dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing plate appearances: 100%|██████████| 100815/100815 [00:23<00:00, 4266.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing datasets f\n"
     ]
    }
   ],
   "source": [
    "# without description_foul_bunt and description_foul_tip + other stuff for live data model integration\n",
    "hasDataSet = os.path.exists('./data/train_dataset_f_emb.pkl')\n",
    "print(hasDataSet)\n",
    "train_dataset, val_dataset = model.load_training_data('./data/final_final_encoded_savant_2024.csv', hasDataSet, './data/batting_stats_23.csv', './data/pitching_stats_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2170518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_final_encoded_savant_2024.csv')\n",
    "# List of memory features (copy from your model)\n",
    "memory_features = [\n",
    "    'release_speed', 'release_pos_y',\n",
    "    'pitch_type_group_BREAK', 'pitch_type_group_FAST', 'pitch_type_group_OFF',\n",
    "    'description_ball', 'description_blocked_ball', 'description_called_strike', 'description_foul', \n",
    "    'description_foul_bunt', 'description_foul_tip', 'description_hit_by_pitch', 'description_hit_into_play', \n",
    "    'description_pitchout', 'description_swinging_strike', 'description_swinging_strike_blocked', \n",
    "    'type_B', 'type_S', 'bb_type_fly_ball', 'bb_type_ground_ball', 'bb_type_line_drive', 'bb_type_popup', \n",
    "    'zone_1.0', 'zone_2.0', 'zone_3.0', 'zone_4.0', 'zone_5.0', 'zone_6.0', 'zone_7.0', 'zone_8.0', \n",
    "    'zone_9.0', 'zone_11.0', 'zone_12.0', 'zone_13.0', 'zone_14.0', 'zone_nan', 'hit_location_1.0', 'hit_location_2.0', \n",
    "    'hit_location_3.0', 'hit_location_4.0', 'hit_location_5.0', 'hit_location_6.0', 'hit_location_7.0', 'hit_location_8.0', \n",
    "    'hit_location_9.0', 'hit_location_nan'\n",
    "]\n",
    "\n",
    "# Number of previous pitches to mock\n",
    "num_prev_pitches = 5\n",
    "\n",
    "# Create random data for each feature\n",
    "mock_data = {}\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Example: assign plausible ranges for numeric features, 0/1 for one-hot/categorical\n",
    "for feature in memory_features:\n",
    "    if feature == 'release_speed':\n",
    "        mock_data[feature] = np.random.uniform(-0.75, 100, num_prev_pitches)  # plausible pitch speeds\n",
    "    elif feature == 'release_pos_y':\n",
    "        mock_data[feature] = np.random.uniform(-0.7, 0.85, num_prev_pitches)   # plausible y positions\n",
    "    else:\n",
    "        # For one-hot/categorical features, use 0 or 1\n",
    "        mock_data[feature] = np.random.randint(0, 2, num_prev_pitches).astype(float)\n",
    "\n",
    "mock_memory = pd.DataFrame(mock_data).to_numpy()\n",
    "context_features = [\n",
    "    'stand_R', 'p_throws_R', 'balls', 'strikes',\n",
    "    'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot_Top', 'at_bat_number', 'pitch_number',\n",
    "    'home_score', 'away_score', 'bat_score', 'fld_score', 'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat',\n",
    "    'prev_runs_scored'\n",
    "]\n",
    "context = df.iloc[100][context_features].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config/specs\n",
    "with open(\"best_pitch_predictor_lstm_meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "for key in meta:\n",
    "    print(key)\n",
    "    if (key == 'lstm_init_args'):\n",
    "        for k in meta[key]:\n",
    "            print('   ', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439453fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import model\n",
    "\n",
    "# Load model config/specs\n",
    "with open(\"best_pitch_predictor_lstm_meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "# Instantiate the model using the loaded specs\n",
    "loaded_mod = model.PitchPredictorLSTM(\n",
    "    context_dim=meta[\"lstm_init_args\"]['context_dim'],\n",
    "    memory_dim=meta[\"lstm_init_args\"]['memory_dim'],\n",
    "    num_pitchers=len(meta[\"pitcher_to_id\"]),\n",
    "    num_batters=len(meta[\"batter_to_id\"]),\n",
    "    pitcher_embed_dim=32,\n",
    "    batter_embed_dim=32,\n",
    "    lstm_hidden_dim=128,\n",
    "    num_pitch_types=4\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "loaded_mod.load_state_dict(torch.load(\"./models/best_pitch_predictor_lstm.pth\", map_location=\"cpu\"))\n",
    "loaded_mod.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2380f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_next_pitch(loaded_mod, current_context=context, pitcher_id=[meta[\"pitcher_to_id\"][506433]], \n",
    "                         batter_id=[meta[\"batter_to_id\"][518595]], previous_pitches_in_pa=mock_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eea45f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAST': 0.4343152940273285,\n",
       " 'OFF': 0.10942773520946503,\n",
       " 'BREAK': 0.4561111330986023,\n",
       " 'OTH': 0.00014581962022930384}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['pitch_type_to_idx']\n",
    "# Map the predicted probabilities to pitch type names using meta['pitch_type_to_idx']\n",
    "# We'll invert the dict to get idx -> pitch_type\n",
    "idx_to_pitch_type = {v: k for k, v in meta['pitch_type_to_idx'].items()}\n",
    "pitch_probs = {idx_to_pitch_type[i]: float(probs[0, i]) for i in range(probs.shape[1])}\n",
    "pitch_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8bb91",
   "metadata": {},
   "source": [
    "#### original model with all savant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initting model architecture\n",
      "starting training loop\n",
      "Epoch 1, Train Loss: 0.8674, Val Loss: 0.8429\n",
      "Epoch 2, Train Loss: 0.8360, Val Loss: 0.8264\n",
      "Epoch 3, Train Loss: 0.8258, Val Loss: 0.8201\n",
      "Epoch 4, Train Loss: 0.8204, Val Loss: 0.8119\n",
      "Epoch 5, Train Loss: 0.8166, Val Loss: 0.8087\n",
      "Epoch 6, Train Loss: 0.8142, Val Loss: 0.8107\n",
      "Epoch 7, Train Loss: 0.8119, Val Loss: 0.8085\n",
      "Epoch 8, Train Loss: 0.8102, Val Loss: 0.8089\n",
      "Epoch 9, Train Loss: 0.8088, Val Loss: 0.8043\n",
      "Epoch 10, Train Loss: 0.8070, Val Loss: 0.8079\n",
      "Epoch 11, Train Loss: 0.8061, Val Loss: 0.8076\n",
      "Epoch 12, Train Loss: 0.8050, Val Loss: 0.8034\n",
      "Epoch 13, Train Loss: 0.8044, Val Loss: 0.8065\n",
      "Epoch 14, Train Loss: 0.8036, Val Loss: 0.8066\n",
      "Epoch 15, Train Loss: 0.8023, Val Loss: 0.8134\n",
      "Epoch 16, Train Loss: 0.8020, Val Loss: 0.8092\n",
      "Epoch 17, Train Loss: 0.8013, Val Loss: 0.8061\n",
      "Epoch 18, Train Loss: 0.8012, Val Loss: 0.8071\n",
      "Epoch 19, Train Loss: 0.8006, Val Loss: 0.8044\n",
      "Epoch 20, Train Loss: 0.7997, Val Loss: 0.8083\n",
      "Epoch 21, Train Loss: 0.7992, Val Loss: 0.8065\n",
      "Epoch 22, Train Loss: 0.7987, Val Loss: 0.8047\n",
      "Early stopping triggered after 22 epochs. Best Val Loss: 0.8034\n"
     ]
    }
   ],
   "source": [
    "lstm_mod = model.train_model(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6770d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model architecture\n",
    "mock_lstm_mod = model.PitchPredictorLSTM(\n",
    "    context_dim=len(context_features),\n",
    "    memory_dim=len(memory_features),\n",
    "    num_pitchers=len(df['pitcher'].unique()),\n",
    "    num_batters=965, #len(df['batter'].unique()),\n",
    "    pitcher_embed_dim=32,\n",
    "    batter_embed_dim=32,\n",
    "    lstm_hidden_dim=128,\n",
    "    num_pitch_types=4\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "mock_lstm_mod.load_state_dict(torch.load('best_pitch_predictor_lstm.pth', map_location='cpu'))\n",
    "mock_lstm_mod.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22032965",
   "metadata": {},
   "source": [
    "## Modified Model W/ Pitcher/Batter MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import model\n",
    "\n",
    "# Load model config/specs\n",
    "with open(\"./models/pitch_predictor_lstm_meta1.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "# Instantiate the model using the loaded specs\n",
    "loaded_mod = model.PitchPredictorLSTM(\n",
    "    context_dim=meta[\"lstm_init_args\"]['context_dim'],\n",
    "    memory_dim=meta[\"lstm_init_args\"]['memory_dim'],\n",
    "    num_pitchers=len(meta[\"pitcher_to_id\"]),\n",
    "    num_batters=len(meta[\"batter_to_id\"]),\n",
    "    pitcher_embed_dim=16,\n",
    "    batter_embed_dim=16,\n",
    "    lstm_hidden_dim=128,\n",
    "    num_pitch_types=4\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "loaded_mod.load_state_dict(torch.load(\"./models/pitch_predictor_lstm1.pth\", map_location=\"cpu\"))\n",
    "loaded_mod.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8972aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_final_encoded_savant_2024.csv')\n",
    "# List of memory features (copy from your model)\n",
    "memory_features = [\n",
    "    'release_speed', 'release_pos_y',\n",
    "    'pitch_type_group_BREAK', 'pitch_type_group_FAST', 'pitch_type_group_OFF',\n",
    "    'description_ball', 'description_blocked_ball', 'description_called_strike', 'description_foul', \n",
    "    'description_foul_bunt', 'description_foul_tip', 'description_hit_by_pitch', 'description_hit_into_play', \n",
    "    'description_pitchout', 'description_swinging_strike', 'description_swinging_strike_blocked', \n",
    "    'type_B', 'type_S'\n",
    "]\n",
    "\n",
    "# Number of previous pitches to mock\n",
    "num_prev_pitches = 3\n",
    "\n",
    "# Create random data for each feature\n",
    "mock_data = {}\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Example: assign plausible ranges for numeric features, 0/1 for one-hot/categorical\n",
    "for feature in memory_features:\n",
    "    if feature == 'release_speed':\n",
    "        mock_data[feature] = np.random.uniform(-0.75, 100, num_prev_pitches)  # plausible pitch speeds\n",
    "    elif feature == 'release_pos_y':\n",
    "        mock_data[feature] = np.random.uniform(-0.7, 0.85, num_prev_pitches)   # plausible y positions\n",
    "    else:\n",
    "        # For one-hot/categorical features, use 0 or 1\n",
    "        mock_data[feature] = np.random.randint(0, 2, num_prev_pitches).astype(float)\n",
    "\n",
    "mock_memory = pd.DataFrame(mock_data).to_numpy()\n",
    "# context_features = [\n",
    "#     'stand_R', 'p_throws_R', 'balls', 'strikes',\n",
    "#     'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot_Top', 'at_bat_number', 'pitch_number',\n",
    "#     'home_score', 'away_score', 'bat_score', 'fld_score', 'n_thruorder_pitcher', 'n_priorpa_thisgame_player_at_bat',\n",
    "#     'prev_runs_scored'\n",
    "# ]\n",
    "context_features = [\n",
    "    'stand_R', 'p_throws_R', 'balls', 'strikes', 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot_Top', \n",
    "    'at_bat_number', 'pitch_number', 'home_score', 'away_score', 'prev_runs_scored'\n",
    "]\n",
    "context = df.iloc[100][context_features].astype(float).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f1f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pitcher, batter data\n",
    "batter_df = pd.read_csv('./data/batting_stats_23.csv')\n",
    "pitcher_df = pd.read_csv('./data/pitching_stats_23.csv')\n",
    "\n",
    "pitcher_stat_cols = ['#days', 'Age', 'G', 'GS', 'W', 'L', 'SV', 'IP', 'H', 'R', 'ER', 'BB', \n",
    "                                  'SO', 'HR', 'HBP', 'ERA', 'AB', '2B', '3B', 'IBB', 'GDP', 'SF', 'SB', 'CS', 'PO', 'BF', 'Pit', \n",
    "                                  'Str', 'StL', 'StS', 'GB/FB', 'LD', 'PU', 'WHIP', 'BAbip', 'SO9', 'SO/W']\n",
    "        \n",
    "batter_stat_cols = ['#days', 'Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', \n",
    "                            'SH', 'SF', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS']\n",
    "\n",
    "# added\n",
    "#print(self.pitcher_stats_df.columns)\n",
    "pitcher_row = pitcher_df[pitcher_df['mlbID'] == 506433]\n",
    "if not pitcher_row.empty:\n",
    "    pitcher_stats_vec = torch.FloatTensor(pitcher_row[pitcher_stat_cols].values[0])\n",
    "else:\n",
    "    pitcher_stats_vec = torch.zeros(len(pitcher_stat_cols))\n",
    "\n",
    "batter_row = batter_df[batter_df['mlbID'] == 518595]\n",
    "if not batter_row.empty:\n",
    "    batter_stats_vec = torch.FloatTensor(batter_row[batter_stat_cols].values[0])\n",
    "else:\n",
    "    batter_stats_vec = torch.zeros(len(batter_stat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1383449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,)\n",
      "torch.Size([37])\n",
      "torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "print(context.shape)\n",
    "print(pitcher_stats_vec.shape)\n",
    "print(batter_stats_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b0aac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3602757e-01, 1.2465691e-01, 2.3922165e-01, 9.3892959e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_next_pitch(loaded_mod, current_context=context, pitcher_id=[meta[\"pitcher_to_id\"][506433]], \n",
    "                         batter_id=[meta[\"batter_to_id\"][518595]], previous_pitches_in_pa=mock_memory,\n",
    "                         pitcher_stats=pitcher_stats_vec.unsqueeze(0), batter_stats=batter_stats_vec.unsqueeze(0))\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56b1e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAST': 0.6360275745391846,\n",
       " 'OFF': 0.12465690821409225,\n",
       " 'BREAK': 0.23922164738178253,\n",
       " 'OTH': 9.389295883011073e-05}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['pitch_type_to_idx']\n",
    "# Map the predicted probabilities to pitch type names using meta['pitch_type_to_idx']\n",
    "# We'll invert the dict to get idx -> pitch_type\n",
    "idx_to_pitch_type = {v: k for k, v in meta['pitch_type_to_idx'].items()}\n",
    "pitch_probs = {idx_to_pitch_type[i]: float(probs[0, i]) for i in range(probs.shape[1])}\n",
    "pitch_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1b0c1",
   "metadata": {},
   "source": [
    "## Modified with more removed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb25c3",
   "metadata": {},
   "source": [
    "#### pitcher game sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca0631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "reading batter csv\n",
      "read batter csv\n",
      "reading pitcher csv\n",
      "read pitcher csv\n",
      "loading train_dataset f from pickle\n",
      "loading val_dataset f from pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "hasDataSet = os.path.exists('./data/train_dataset_pitcher.pkl')\n",
    "print(hasDataSet)\n",
    "train_dataset, val_dataset = model.load_training_data('./data/player_game_savant.csv', hasDataSet, './data/batting_stats_23.csv', './data/pitching_stats_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334eea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initting model architecture\n",
      "starting training loop\n",
      "Epoch 1, Train Loss: 0.9004, Val Loss: 0.9194\n",
      "Epoch 2, Train Loss: 0.8891, Val Loss: 0.9165\n",
      "Epoch 3, Train Loss: 0.8871, Val Loss: 0.9177\n",
      "Epoch 4, Train Loss: 0.8864, Val Loss: 0.9170\n",
      "Epoch 5, Train Loss: 0.8855, Val Loss: 0.9129\n",
      "Epoch 6, Train Loss: 0.8848, Val Loss: 0.9159\n",
      "Epoch 7, Train Loss: 0.8842, Val Loss: 0.9131\n",
      "Epoch 8, Train Loss: 0.8840, Val Loss: 0.9123\n",
      "Epoch 9, Train Loss: 0.8837, Val Loss: 0.9189\n",
      "Epoch 10, Train Loss: 0.8835, Val Loss: 0.9128\n",
      "Epoch 11, Train Loss: 0.8832, Val Loss: 0.9120\n",
      "Epoch 12, Train Loss: 0.8831, Val Loss: 0.9162\n",
      "Epoch 13, Train Loss: 0.8831, Val Loss: 0.9146\n",
      "Epoch 14, Train Loss: 0.8830, Val Loss: 0.9133\n",
      "Epoch 15, Train Loss: 0.8826, Val Loss: 0.9141\n",
      "Epoch 16, Train Loss: 0.8826, Val Loss: 0.9146\n",
      "Epoch 17, Train Loss: 0.8826, Val Loss: 0.9133\n",
      "Epoch 18, Train Loss: 0.8826, Val Loss: 0.9136\n",
      "Epoch 19, Train Loss: 0.8823, Val Loss: 0.9120\n",
      "Epoch 20, Train Loss: 0.8822, Val Loss: 0.9120\n",
      "Epoch 21, Train Loss: 0.8822, Val Loss: 0.9137\n",
      "Epoch 22, Train Loss: 0.8820, Val Loss: 0.9108\n",
      "Epoch 23, Train Loss: 0.8820, Val Loss: 0.9136\n",
      "Epoch 24, Train Loss: 0.8818, Val Loss: 0.9091\n",
      "Epoch 25, Train Loss: 0.8822, Val Loss: 0.9120\n",
      "Epoch 26, Train Loss: 0.8819, Val Loss: 0.9121\n",
      "Epoch 27, Train Loss: 0.8820, Val Loss: 0.9123\n",
      "Epoch 28, Train Loss: 0.8818, Val Loss: 0.9106\n",
      "Epoch 29, Train Loss: 0.8817, Val Loss: 0.9122\n",
      "Epoch 30, Train Loss: 0.8815, Val Loss: 0.9119\n",
      "Epoch 31, Train Loss: 0.8818, Val Loss: 0.9118\n",
      "Epoch 32, Train Loss: 0.8818, Val Loss: 0.9121\n",
      "Epoch 33, Train Loss: 0.8816, Val Loss: 0.9139\n",
      "Epoch 34, Train Loss: 0.8816, Val Loss: 0.9107\n",
      "Early stopping triggered after 34 epochs. Best Val Loss: 0.9091\n"
     ]
    }
   ],
   "source": [
    "# PITCHER-GAME sequences | without description_foul_bunt and description_foul_tip + other stuff for live data model integration\n",
    "lstm_mod = model.train_model(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d75433",
   "metadata": {},
   "source": [
    "#### pitcher-plate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266454b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "reading batter csv\n",
      "read batter csv\n",
      "reading pitcher csv\n",
      "read pitcher csv\n",
      "reading dataset csv\n",
      "read dataset csv\n",
      "processing train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing plate appearances: 100%|██████████| 179716/179716 [02:33<00:00, 1173.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing val dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing plate appearances: 100%|██████████| 100815/100815 [00:23<00:00, 4266.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing datasets f\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# without description_foul_bunt and description_foul_tip + other stuff for live data model integration\n",
    "hasDataSet = os.path.exists('./data/train_dataset_f_emb.pkl')\n",
    "print(hasDataSet)\n",
    "train_dataset, val_dataset = model.load_training_data('./data/final_final_encoded_savant_2024.csv', hasDataSet, './data/batting_stats_23.csv', './data/pitching_stats_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initting model architecture\n",
      "starting training loop\n",
      "Epoch 1, Train Loss: 0.9305, Val Loss: 0.9351\n",
      "Epoch 2, Train Loss: 0.9199, Val Loss: 0.9304\n",
      "Epoch 3, Train Loss: 0.9178, Val Loss: 0.9328\n",
      "Epoch 4, Train Loss: 0.9170, Val Loss: 0.9294\n",
      "Epoch 5, Train Loss: 0.9159, Val Loss: 0.9309\n",
      "Epoch 6, Train Loss: 0.9153, Val Loss: 0.9286\n",
      "Epoch 7, Train Loss: 0.9148, Val Loss: 0.9280\n",
      "Epoch 8, Train Loss: 0.9144, Val Loss: 0.9296\n",
      "Epoch 9, Train Loss: 0.9143, Val Loss: 0.9298\n",
      "Epoch 10, Train Loss: 0.9142, Val Loss: 0.9305\n",
      "Epoch 11, Train Loss: 0.9140, Val Loss: 0.9304\n",
      "Epoch 12, Train Loss: 0.9139, Val Loss: 0.9282\n",
      "Epoch 13, Train Loss: 0.9138, Val Loss: 0.9281\n",
      "Epoch 14, Train Loss: 0.9137, Val Loss: 0.9284\n",
      "Epoch 15, Train Loss: 0.9137, Val Loss: 0.9271\n",
      "Epoch 16, Train Loss: 0.9134, Val Loss: 0.9265\n",
      "Epoch 17, Train Loss: 0.9134, Val Loss: 0.9261\n",
      "Epoch 18, Train Loss: 0.9132, Val Loss: 0.9278\n",
      "Epoch 19, Train Loss: 0.9130, Val Loss: 0.9299\n",
      "Epoch 20, Train Loss: 0.9126, Val Loss: 0.9276\n",
      "Epoch 21, Train Loss: 0.9129, Val Loss: 0.9288\n",
      "Epoch 22, Train Loss: 0.9128, Val Loss: 0.9303\n",
      "Epoch 23, Train Loss: 0.9130, Val Loss: 0.9286\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# without description_foul_bunt and description_foul_tip + other stuff for live data model integration\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m lstm_mod \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/data-analysis/model.py:354\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_dataset, val_dataset)\u001b[0m\n",
      "\u001b[1;32m    351\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "\u001b[1;32m    353\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;32m--> 354\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    355\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;32m    357\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n",
      "\u001b[1;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m    483\u001b[0m             )\n",
      "\u001b[0;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\u001b[0;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n",
      "\u001b[1;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n",
      "\u001b[1;32m    237\u001b[0m         group,\n",
      "\u001b[1;32m    238\u001b[0m         params_with_grad,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    243\u001b[0m         state_steps,\n",
      "\u001b[1;32m    244\u001b[0m     )\n",
      "\u001b[0;32m--> 246\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoupled_weight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n",
      "\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n",
      "\u001b[0;32m--> 933\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/personal-projects/pitch-predictor/.venv/lib/python3.9/site-packages/torch/optim/adam.py:525\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n",
      "\u001b[1;32m    523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 525\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[1;32m    527\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# without description_foul_bunt and description_foul_tip + other stuff for live data model integration\n",
    "lstm_mod = model.train_model(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9318c3",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00269e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config/specs\n",
    "with open(\"./pitch_predictor_lstm_meta1.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "\n",
    "# Instantiate the model using the loaded specs\n",
    "loaded_mod = model.PitchPredictorLSTM(\n",
    "    context_dim=meta[\"lstm_init_args\"]['context_dim'],\n",
    "    memory_dim=meta[\"lstm_init_args\"]['memory_dim'],\n",
    "    num_pitchers=len(meta[\"pitcher_to_id\"]),\n",
    "    num_batters=len(meta[\"batter_to_id\"]),\n",
    "    pitcher_embed_dim=16,\n",
    "    batter_embed_dim=16,\n",
    "    lstm_hidden_dim=128,\n",
    "    num_pitch_types=4\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "loaded_mod.load_state_dict(torch.load(\"./pitch_predictor_lstm1.pth\", map_location=\"cpu\"))\n",
    "loaded_mod.eval()\n",
    "\n",
    "df = pd.read_csv('./data/final_final_encoded_savant_2024.csv')\n",
    "# List of memory features (copy from your model)\n",
    "memory_features = [\n",
    "    'release_speed', # 'release_pos_y',\n",
    "    'pitch_type_group_BREAK', 'pitch_type_group_FAST', 'pitch_type_group_OFF',\n",
    "    'description_ball', 'description_blocked_ball', 'description_called_strike', 'description_foul', \n",
    "    'description_hit_by_pitch', 'description_hit_into_play', #'description_foul_bunt', 'description_foul_tip', \n",
    "    'description_pitchout', 'description_swinging_strike', # 'description_swinging_strike_blocked', \n",
    "    'type_B', 'type_S'\n",
    "]\n",
    "\n",
    "# Number of previous pitches to mock\n",
    "num_prev_pitches = 3\n",
    "\n",
    "# Create random data for each feature\n",
    "mock_data = {}\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Example: assign plausible ranges for numeric features, 0/1 for one-hot/categorical\n",
    "for feature in memory_features:\n",
    "    if feature == 'release_speed':\n",
    "        mock_data[feature] = np.random.uniform(-0.75, 100, num_prev_pitches)  # plausible pitch speeds\n",
    "    elif feature == 'release_pos_y':\n",
    "        mock_data[feature] = np.random.uniform(-0.7, 0.85, num_prev_pitches)   # plausible y positions\n",
    "    else:\n",
    "        # For one-hot/categorical features, use 0 or 1\n",
    "        mock_data[feature] = np.random.randint(0, 2, num_prev_pitches).astype(float)\n",
    "\n",
    "mock_memory = pd.DataFrame(mock_data).to_numpy()\n",
    "context_features = [\n",
    "    'p_throws_R', 'balls', 'strikes', 'on_3b', 'on_2b', 'on_1b', 'outs_when_up', 'inning', 'inning_topbot_Top', \n",
    "    'at_bat_number', 'pitch_number', 'home_score', 'away_score', 'prev_runs_scored' #'stand_R', \n",
    "]\n",
    "context = df.iloc[100][context_features].astype(float).values\n",
    "\n",
    "# load pitcher, batter data\n",
    "batter_df = pd.read_csv('./data/batting_stats_23.csv')\n",
    "pitcher_df = pd.read_csv('./data/pitching_stats_23.csv')\n",
    "\n",
    "pitcher_stat_cols = ['#days', 'Age', 'G', 'GS', 'W', 'L', 'SV', 'IP', 'H', 'R', 'ER', 'BB', \n",
    "                                  'SO', 'HR', 'HBP', 'ERA', 'AB', '2B', '3B', 'IBB', 'GDP', 'SF', 'SB', 'CS', 'PO', 'BF', 'Pit', \n",
    "                                  'Str', 'StL', 'StS', 'GB/FB', 'LD', 'PU', 'WHIP', 'BAbip', 'SO9', 'SO/W']\n",
    "        \n",
    "batter_stat_cols = ['#days', 'Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', \n",
    "                            'SH', 'SF', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS']\n",
    "\n",
    "# added\n",
    "#print(self.pitcher_stats_df.columns)\n",
    "pitcher_row = pitcher_df[pitcher_df['mlbID'] == 506433]\n",
    "if not pitcher_row.empty:\n",
    "    pitcher_stats_vec = torch.FloatTensor(pitcher_row[pitcher_stat_cols].values[0])\n",
    "else:\n",
    "    pitcher_stats_vec = torch.zeros(len(pitcher_stat_cols))\n",
    "\n",
    "batter_row = batter_df[batter_df['mlbID'] == 518595]\n",
    "if not batter_row.empty:\n",
    "    batter_stats_vec = torch.FloatTensor(batter_row[batter_stat_cols].values[0])\n",
    "else:\n",
    "    batter_stats_vec = torch.zeros(len(batter_stat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f69b3fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3943422e-01, 6.0463212e-02, 3.0004773e-01, 5.4788296e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_next_pitch(loaded_mod, current_context=context, pitcher_id=[meta[\"pitcher_to_id\"][506433]], \n",
    "                         batter_id=[meta[\"batter_to_id\"][518595]], previous_pitches_in_pa=mock_memory,\n",
    "                         pitcher_stats=pitcher_stats_vec.unsqueeze(0), batter_stats=batter_stats_vec.unsqueeze(0))\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78206f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import pickle\n",
    "import torch\n",
    "with open(\"./models/lstm_game_history_meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "batter_df = pd.read_csv('./data/batting_stats_23.csv')\n",
    "pitcher_df = pd.read_csv('./data/pitching_stats_23.csv')\n",
    "with open('./data/val_dataset_pitcher.pkl', 'rb') as f:\n",
    "            val_dataset = pickle.load(f)\n",
    "            \n",
    "pitcher_stat_cols = ['#days', 'Age', 'G', 'GS', 'W', 'L', 'SV', 'IP', 'H', 'R', 'ER', 'BB', \n",
    "                                  'SO', 'HR', 'HBP', 'ERA', 'AB', '2B', '3B', 'IBB', 'GDP', 'SF', 'SB', 'CS', 'PO', 'BF', 'Pit', \n",
    "                                  'Str', 'StL', 'StS', 'GB/FB', 'LD', 'PU', 'WHIP', 'BAbip', 'SO9', 'SO/W']\n",
    "        \n",
    "batter_stat_cols = ['#days', 'Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', \n",
    "                            'SH', 'SF', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS']\n",
    "count = 0\n",
    "correct = 0\n",
    "non_fast_pred_count = 0\n",
    "for context, pitcher_id, batter_id, memory_seq, pitcher_stats, batter_stats, target in val_dataset:\n",
    "\n",
    "    pitcher_row = pitcher_df[pitcher_df['mlbID'] == pitcher_id]\n",
    "    if not pitcher_row.empty:\n",
    "        pitcher_stats_vec = torch.FloatTensor(pitcher_row[pitcher_stat_cols].values[0])\n",
    "    else:\n",
    "        pitcher_stats_vec = torch.zeros(len(pitcher_stat_cols))\n",
    "\n",
    "    batter_row = batter_df[batter_df['mlbID'] == batter_id]\n",
    "    if not batter_row.empty:\n",
    "        batter_stats_vec = torch.FloatTensor(batter_row[batter_stat_cols].values[0])\n",
    "    else:\n",
    "        batter_stats_vec = torch.zeros(len(batter_stat_cols))\n",
    "\n",
    "    probs = model.predict_next_pitch(lstm_mod, current_context=context, pitcher_id=[pitcher_id.item()], \n",
    "                    batter_id=[batter_id.item()], previous_pitches_in_pa=memory_seq,\n",
    "                    pitcher_stats=pitcher_stats_vec.unsqueeze(0), batter_stats=batter_stats_vec.unsqueeze(0))\n",
    "    \n",
    "\n",
    "    idx_to_pitch_type = {v: k for k, v in meta['pitch_type_to_idx'].items()}\n",
    "    probs = {idx_to_pitch_type[i]: float(probs[0, i]) for i in range(probs.shape[1])}\n",
    "    # pitch_probs\n",
    "\n",
    "    highest_key = ''\n",
    "    highest_prob = 0\n",
    "    #print(probs)\n",
    "    for key in probs:\n",
    "        if probs[key] > highest_prob:\n",
    "            highest_prob = probs[key]\n",
    "            highest_key = key\n",
    "    \n",
    "    pitch_types = ['FAST', 'OFF', 'BREAK', 'OTH']\n",
    "    print(f'Actual: {pitch_types[target]} Predicted: {highest_key} with prob {highest_prob: 0.4f}')\n",
    "    count+=1\n",
    "    if (highest_key != 'FAST'):\n",
    "        non_fast_pred_count += 1\n",
    "    if (pitch_types[target] == highest_key):\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add2f89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5665349355698108"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
